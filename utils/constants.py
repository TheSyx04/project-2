"""
This file contains all the constants used in the abstractive summarization task.
"""

import torch

RESULTS_DIR = "./results/"
SEED = 42

# General hyperparameters
MAX_SOURCE_LENGTH = 1024
MAX_TARGET_LENGTH = 256
NUM_BEAMS = 4
LENGTH_PENALTY = 2.0
EARLY_STOPPING = True

# [1. T5 SUMMARIZATION HYPERPARAMETERS]
MODEL_T5 = "t5-small"
TOKENIZER_T5 = "t5-small"

RESULTS_DIR_T5 = RESULTS_DIR + "t5/"
EXPERIMENT_NAME_T5 = "t5-experiment"
EXPERIMENT_RESULTS_DIR_T5 = RESULTS_DIR_T5 + EXPERIMENT_NAME_T5

LR_T5 = 3e-5
TRAIN_BATCH_SIZE_T5 = 1
EVAL_BATCH_SIZE_T5 = 1
NUM_TRAIN_EPOCHS_T5 = 2
WEIGHT_DECAY_T5 = 0.01
EVAL_STEPS_T5 = 1000
SAVE_STEPS_T5 = 1000
GRADIENT_ACCUMULATION_STEPS_T5 = 1

LOGGING_STEPS_T5 = 100

# [2. BART SUMMARIZATION HYPERPARAMETERS]
MODEL_BART = "facebook/bart-base"
TOKENIZER_BART = "facebook/bart-base"

RESULTS_DIR_BART = RESULTS_DIR + "bart/"
EXPERIMENT_NAME_BART = "bart-experiment-test"
EXPERIMENT_RESULTS_DIR_BART = RESULTS_DIR_BART + EXPERIMENT_NAME_BART

LR_BART = 3e-5
TRAIN_BATCH_SIZE_BART = 1
EVAL_BATCH_SIZE_BART = 1
NUM_TRAIN_EPOCHS_BART = 2
WEIGHT_DECAY_BART = 0.01
EVAL_STEPS_BART = 50
SAVE_STEPS_BART = 50
GRADIENT_ACCUMULATION_STEPS_BART = 1

LOGGING_STEPS_BART = 10

# [3. PEGASUS SUMMARIZATION HYPERPARAMETERS]
MODEL_PEGASUS = "google/pegasus-cnn_dailymail"
TOKENIZER_PEGASUS = "google/pegasus-cnn_dailymail"

RESULTS_DIR_PEGASUS = RESULTS_DIR + "pegasus/"
EXPERIMENT_NAME_PEGASUS = "pegasus-experiment-3"
EXPERIMENT_RESULTS_DIR_PEGASUS = RESULTS_DIR_PEGASUS + EXPERIMENT_NAME_PEGASUS

LR_PEGASUS = 3e-5
TRAIN_BATCH_SIZE_PEGASUS = 1
EVAL_BATCH_SIZE_PEGASUS = 1
NUM_TRAIN_EPOCHS_PEGASUS = 1
WEIGHT_DECAY_PEGASUS = 0.01
EVAL_STEPS_PEGASUS = 50000
SAVE_STEPS_PEGASUS = 50000
GRADIENT_ACCUMULATION_STEPS_PEGASUS = 1

LOGGING_STEPS_PEGASUS = 10
