"""
This file contains all the constants used in the abstractive summarization task.
"""

import torch

RESULTS_DIR = "./results/"
SEED = 42

# General hyperparameters
MAX_SOURCE_LENGTH = 1024
MAX_TARGET_LENGTH = 256
NUM_BEAMS = 4
LENGTH_PENALTY = 2.0
EARLY_STOPPING = True

# [1. T5 SUMMARIZATION HYPERPARAMETERS]
MODEL_T5 = "t5-small"
TOKENIZER_T5 = "t5-small"

RESULTS_DIR_T5 = RESULTS_DIR + "t5/"
EXPERIMENT_NAME_T5 = "t5-experiment"
EXPERIMENT_RESULTS_DIR_T5 = RESULTS_DIR_T5 + EXPERIMENT_NAME_T5

LR_T5 = 3e-5
TRAIN_BATCH_SIZE_T5 = 1
EVAL_BATCH_SIZE_T5 = 1
NUM_TRAIN_EPOCHS_T5 = 2
WEIGHT_DECAY_T5 = 0.01
EVAL_STEPS_T5 = 1000
SAVE_STEPS_T5 = 1000
GRADIENT_ACCUMULATION_STEPS_T5 = 1

LOGGING_STEPS_T5 = 100

# [2. BART SUMMARIZATION HYPERPARAMETERS]
MODEL_BART = "facebook/bart-base"
TOKENIZER_BART = "facebook/bart-base"

RESULTS_DIR_BART = RESULTS_DIR + "bart/"
EXPERIMENT_NAME_BART = "bart-experiment-2"
EXPERIMENT_RESULTS_DIR_BART = RESULTS_DIR_BART + EXPERIMENT_NAME_BART

LR_BART = 5e-5
TRAIN_BATCH_SIZE_BART = 1
EVAL_BATCH_SIZE_BART = 1
NUM_TRAIN_EPOCHS_BART = 10
WEIGHT_DECAY_BART = 0.01
EVAL_STEPS_BART = 1000
SAVE_STEPS_BART = 1000
GRADIENT_ACCUMULATION_STEPS_BART = 1

LOGGING_STEPS_BART = 100

